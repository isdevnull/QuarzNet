{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quarznet-librispeech.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UeZpvJ318uF",
        "outputId": "ad0ddf32-0afe-4b7c-ce4a-6eb92da73021"
      },
      "source": [
        "!pip install -qq torchaudio\n",
        "!pip install -qq torch_optimizer\n",
        "!pip install -qq editdistance\n",
        "!pip install -qq wandb\n",
        "!pip install -qq git+https://github.com/albumentations-team/albumentations.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71mHdy1m1oZa"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torchaudio\n",
        "from torch import nn\n",
        "import torch_optimizer\n",
        "import sys\n",
        "from torch.utils.data import DataLoader\n",
        "from torchaudio.transforms import MelSpectrogram\n",
        "import albumentations as A\n",
        "from drive.MyDrive.quarznet.model.QuarzNet import QuarzNet5x3"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6rzlTa1YCts"
      },
      "source": [
        "# from https://stackoverflow.com/questions/57416925/best-practices-for-generating-a-random-seeds-to-seed-pytorch\n",
        "def seed_everything(seed=42):\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9gzVseH1tNG"
      },
      "source": [
        "train_ls = torchaudio.datasets.LIBRISPEECH(root=\"./\", url=\"train-clean-100\", download=True)\n",
        "test_ls = torchaudio.datasets.LIBRISPEECH(root=\"./\", url=\"test-clean\", download=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiEu-qbV3hOA"
      },
      "source": [
        "import wandb\n",
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKRcvJlbauPG"
      },
      "source": [
        "quarznet5x3_config = {\n",
        "    'sample_rate': 16000,\n",
        "    'n_mels': 128,\n",
        "    'labels': 29,\n",
        "    'blank_idx': 28,\n",
        "    'train_batch_size': 32,\n",
        "    'test_batch_size': 32,\n",
        "    'spectral_augmentation': False,\n",
        "    'spectral_cutout': True,\n",
        "    'holes': 24,\n",
        "    'epochs': 40,\n",
        "    'lr': 0.015,\n",
        "    'beta1': 0.95,\n",
        "    'beta2': 0.25,\n",
        "    'weight_decay': 0.001\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ty_3lxnl0FDE"
      },
      "source": [
        "sys.path.append('/content/drive/MyDrive/quarznet/utils')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdqQXe8GyJ9A"
      },
      "source": [
        "from TextTransforms import TextTransform, greedy_path_search\n",
        "from DataTransforms import DataCollate\n",
        "from metrics import WER, CER"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzmoWUtt3vNl"
      },
      "source": [
        "wandb.init(project='quarznet5x3', config=quarznet5x3_config, resume=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES_7WN1aS-ER"
      },
      "source": [
        "seed_everything()\n",
        "train_dataloader = DataLoader(train_ls, wandb.config['train_batch_size'], collate_fn=DataCollate(n_mels=wandb.config['n_mels'], specCut=True, holes=wandb.config['holes']), shuffle=True, num_workers=2)\n",
        "test_dataloader = DataLoader(test_ls, wandb.config['test_batch_size'], collate_fn=DataCollate(n_mels=wandb.config['n_mels']), num_workers=2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6ueGWXc9LRB"
      },
      "source": [
        "def trainEpoch(train_dataloader, model, criterion, optimizer, scheduler, scaler, epoch: int, device='cuda:0'):\n",
        "  model.train()\n",
        "  criterion_loss = []\n",
        "  for (i, data) in enumerate(train_dataloader):\n",
        "    spectrogram, targets, input_lengths, target_lengths = data\n",
        "    spectrogram, targets = spectrogram.to(device), targets.to(device)\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    with torch.cuda.amp.autocast():\n",
        "      log_probs = nn.functional.log_softmax(model(spectrogram), dim=1)\n",
        "      loss = criterion(log_probs.permute(2, 0, 1), targets, input_lengths, target_lengths)\n",
        "\n",
        "    criterion_loss.append(loss.item())\n",
        "    \n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scheduler.step()\n",
        "    scaler.update()\n",
        "\n",
        "  avg_loss = sum(criterion_loss) / len(criterion_loss)\n",
        "  wandb.log({'train_loss': avg_loss})\n",
        "  print(f\"Train Epoch[{epoch}]. loss: {avg_loss} \")\n",
        "\n",
        "  return avg_loss\n",
        "\n",
        "@torch.no_grad()\n",
        "def testEpoch(test_dataloader, model, criterion, scaler, epoch: int, device='cuda:0'):\n",
        "    model.eval()\n",
        "    criterion_loss = []\n",
        "    wer = []\n",
        "    cer = []\n",
        "    for i, data in enumerate(test_dataloader):\n",
        "      spectrogram, targets, input_lengths, target_lengths = data\n",
        "      spectrogram, targets = spectrogram.to(device), targets.to(device)\n",
        "\n",
        "      with torch.cuda.amp.autocast():\n",
        "        log_probs = nn.functional.log_softmax(model(spectrogram), dim=1)\n",
        "        loss = criterion(log_probs.permute(2, 0, 1), targets, input_lengths, target_lengths)\n",
        "\n",
        "      scaler.scale(loss)\n",
        "      criterion_loss.append(loss.item())\n",
        "      \n",
        "\n",
        "      sequences = log_probs.argmax(1)\n",
        "      for k, target in enumerate(targets):\n",
        "        hypothesis, reference = greedy_path_search(TextTransform(), sequences[k], target, target_lengths[k])\n",
        "        cur_wer = WER(hypothesis.split(), reference.split())\n",
        "        cur_cer = CER(hypothesis, reference)\n",
        "        wer.append(cur_wer)\n",
        "        cer.append(cur_cer)\n",
        "        \n",
        "\n",
        "    avg_loss = sum(criterion_loss) / len(criterion_loss)\n",
        "    avg_wer = sum(wer) / len(wer)\n",
        "    avg_cer = sum(cer) / len(cer)\n",
        "    wandb.log({\n",
        "        'test_loss': avg_loss,\n",
        "        'WER': avg_wer,\n",
        "        'CER': avg_cer\n",
        "    })\n",
        "    print(f\"Test Epoch[{epoch}]. loss: {avg_loss}; wer: {avg_wer}; cer: {avg_cer} \")\n",
        "\n",
        "    return avg_loss, avg_wer\n",
        "      "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yf__ziPCfVR",
        "outputId": "d35e6089-6d7d-4e8e-e60b-2f4b2d7d9f11"
      },
      "source": [
        "seed_everything()\n",
        "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"device: {DEVICE}\")\n",
        "model = QuarzNet5x3(n_mels=wandb.config['n_mels'], labels=wandb.config['labels'])\n",
        "model = model.to('cuda:0')\n",
        "criterion = nn.CTCLoss(blank=wandb.config['blank_idx']).to(DEVICE)\n",
        "novograd = torch_optimizer.NovoGrad(model.parameters(), lr=wandb.config['lr'] ,betas=(wandb.config['beta1'], wandb.config['beta2']), weight_decay=wandb.config['weight_decay'])\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(novograd, 1000)\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4AEddJwAWjD",
        "outputId": "20a33021-4bfc-4ada-cf3f-eaec1a2e272f"
      },
      "source": [
        "wandb.watch(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<wandb.wandb_torch.TorchGraph at 0x7fabafa6e8d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "id": "fIbMTsrXaf2C",
        "outputId": "01c55018-36c2-49e9-8430-2660067556c6"
      },
      "source": [
        "checkpoint = {}\n",
        "for i in range(1, wandb.config['epochs'] + 1):\n",
        "  trainEpoch(train_dataloader, model, criterion, novograd, scheduler, scaler, i, DEVICE)\n",
        "  testEpoch(test_dataloader, model, criterion, scaler, i, DEVICE)\n",
        "  if i % 5 == 0:\n",
        "    checkpoint = {\n",
        "      'epoch': i,\n",
        "      'state_dict': model.state_dict(),\n",
        "      'optimizer': novograd.state_dict(),\n",
        "      'scheduler': scheduler.state_dict(),\n",
        "      'scaler': scaler.state_dict()\n",
        "    }\n",
        "    torch.save(checkpoint, f'/content/drive/MyDrive/quarznet/checkpoints_5x3_cutouts128/model_state{i}.pt')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch[1]. loss: 2.439578383626425 \n",
            "Test Epoch[1]. loss: 1.849220648044493; wer: 0.9613689187016096; cer: 0.7683015229177264 \n",
            "Train Epoch[2]. loss: 1.5636070939992042 \n",
            "Test Epoch[2]. loss: 1.286498380143468; wer: 0.9163609570419777; cer: 0.7130836878269521 \n",
            "Train Epoch[3]. loss: 1.2497756378265774 \n",
            "Test Epoch[3]. loss: 1.1115765077311819; wer: 0.8935426522197566; cer: 0.6990423178146049 \n",
            "Train Epoch[4]. loss: 1.0862405755861992 \n",
            "Test Epoch[4]. loss: 1.0468240576546366; wer: 0.8868267258377311; cer: 0.6942301708404202 \n",
            "Train Epoch[5]. loss: 0.9819518660483338 \n",
            "Test Epoch[5]. loss: 1.0245512564007828; wer: 0.8809716216170617; cer: 0.6882509853300528 \n",
            "Train Epoch[6]. loss: 0.9070724264923232 \n",
            "Test Epoch[6]. loss: 0.9965544321188112; wer: 0.876632062774684; cer: 0.6872719025517232 \n",
            "Train Epoch[7]. loss: 0.8508413179439279 \n",
            "Test Epoch[7]. loss: 1.0432480391932697; wer: 0.8831011478223296; cer: 0.6881551117089934 \n",
            "Train Epoch[8]. loss: 0.8070951626707086 \n",
            "Test Epoch[8]. loss: 0.9817463595692705; wer: 0.8711391652472271; cer: 0.6836767349772461 \n",
            "Train Epoch[9]. loss: 0.773897201557865 \n",
            "Test Epoch[9]. loss: 0.9645877560464348; wer: 0.870087386162628; cer: 0.678464557631361 \n",
            "Train Epoch[10]. loss: 0.7659967298464925 \n",
            "Test Epoch[10]. loss: 0.7049606518774498; wer: 0.8164383587672536; cer: 0.6547772825192641 \n",
            "Train Epoch[11]. loss: 0.7445202230605309 \n",
            "Test Epoch[11]. loss: 0.7007585811178859; wer: 0.817567740178117; cer: 0.6543526431212742 \n",
            "Train Epoch[12]. loss: 0.7155545665945173 \n",
            "Test Epoch[12]. loss: 0.714944675201323; wer: 0.8172579447254605; cer: 0.6543270570239629 \n",
            "Train Epoch[13]. loss: 0.691459068769564 \n",
            "Test Epoch[13]. loss: 0.7402082125588161; wer: 0.8241397032167089; cer: 0.6562881653224832 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-14cfa9ad4e8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mtrainEpoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnovograd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mtestEpoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-13a1a7480b91>\u001b[0m in \u001b[0;36mtrainEpoch\u001b[0;34m(train_dataloader, model, criterion, optimizer, scheduler, scaler, epoch, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOaKfPXTN0-s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}